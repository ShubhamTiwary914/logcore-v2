version: '3'

env:
  VERNE_NAMESPACE: verne
  MONITOR_NAMESPACE: monitor
  GRAFANA_PASS: prom-operator

tasks:
  ns-create:
    desc: create all required namespaces
    cmds:
      - pwd
      - kubectl apply -f ./k8s/namespaces/

  monitor-deploy:
    desc: helm upgrade the prom-operator pods (afterany config changes)
    cmds: 
      - >
        helm upgrade --install kube-prometheus-stack 
        prometheus-community/kube-prometheus-stack 
        --namespace $MONITOR_NAMESPACE 
        --values ./k8s/monitor/prometheus-operator.yaml

  monitor-destroy:
    desc: helm destroy the monitoring stack
    cmds:
      - helm uninstall kube-prometheus-stack --namespace $MONITOR_NAMESPACE

  grafana-expose:
    desc: export grafana on port 3000 to monitor the k8s pods & metrics
    cmds:
      - |
        export POD_NAME=$(kubectl --namespace $MONITOR_NAMESPACE get pod -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=kube-prometheus-stack" -oname)
        kubectl --namespace $MONITOR_NAMESPACE port-forward $POD_NAME 3000 

  verne-deploy:
    desc: deploy verneMQTT cluster
    deps: [ns-create]
    cmds: 
      - kubectl apply -f ./k8s/vernemq/verne-roles.yaml
      - kubectl apply -f ./k8s/vernemq/verne-depl.yaml
      - kubectl apply -f ./k8s/vernemq/verne-service.yaml

  verne-destroy:
    desc: destroy the verneMQTT & related pods
    cmds: 
      - kubectl delete namespace verne
  
  verne-update:
    desc: update (rolling restart) for verne ns - when making config changes
    cmds:
      - kubectl apply -f ./k8s/vernemq/verne-depl.yaml
      - kubectl rollout restart deployment -n verne

  verne-check-updates:
    desc: updates history for verneMQ namespace
    cmds:
      - kubectl rollout history deployment -n verne

  verne-get-ip:
    desc: get verne broker load balancer IP to access 
    cmds:
      - kubectl get svc vernemq-broker -n verne -o jsonpath='{.spec.clusterIP}'

  locust-build:
    dir: ./services/locust/
    desc: rebuild the locust source image from Dockerfile
    cmds:
      - docker build -t locust-loader:latest .
  
  locust-expose:
    dir: ./services/locust/
    desc: run locust web ui locally to start load testing
    cmds:
      - zsh -i -c "conda activate logcore && locust"

  listener-build:
    dir: ./services/listener
    desc: rebuild the listener source image from Dockerfile
    cmds:
      - docker build --no-cache -t verne-listener:v1.1 .

  listener-push:
    desc: push the listener image to dockerhub
    cmds: 
      - docker tag verne-listener:v1.1 sardinesszsz/verne-listener:v1.1
      - docker push sardinesszsz/verne-listener:v1.1 

  gcp-local-run:
    dir: ./services/gcp
    desc: run the gcp local emulator 
    cmds:
      - bash -c "./run.sh"
  
  gcp-local-init:
    dir: ./services/gcp
    desc: initialize gcp local pubsub(topics) & bigtable(relations)
    cmds:
      - bash -c ""./pubsub/create-topic.sh
      - zsh -i -c "conda activate logcore && python ./bigtable/init.py"
  
  gcp-local-bigtable-get-relations-list:
    dir: ./services/gcp/bigtable
    desc: get list of test relations on bigtable(local)
    cmds:
      - zsh -i -c "conda activate logcore && python list-relations.py"

  gcp-local-bigtable-query:
    dir: ./services/gcp/bigtable
    desc: get list of test relations on bigtable(local) [ARGS- relation]
    cmds:
      - zsh -i -c "conda activate logcore && python query.py --relation {{.CLI_ARGS}}"

  gcp-local-bigtable-clear-relation:
    dir: ./services/gcp/bigtable
    desc: clear all entries of relations on bigtable(local) [ARGS- relation]
    cmds:
      - zsh -i -c "conda activate logcore && python clear.py --relation {{.CLI_ARGS}}"